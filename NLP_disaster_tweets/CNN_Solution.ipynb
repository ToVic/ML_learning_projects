{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only thing that differs from the RNN approach is actually the model so I just copy the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid',palette='muted',font_scale=1.5)\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 16,10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword location                                               text  target\n",
       "id                                                                            \n",
       "1      NaN      NaN  Our Deeds are the Reason of this #earthquake M...       1\n",
       "4      NaN      NaN             Forest fire near La Ronge Sask. Canada       1\n",
       "5      NaN      NaN  All residents asked to 'shelter in place' are ...       1\n",
       "6      NaN      NaN  13,000 people receive #wildfires evacuation or...       1\n",
       "7      NaN      NaN  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.read_csv('train.csv',index_col='id')\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'target'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = raw.drop(['keyword','location'], axis=1)\n",
    "raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw['text']\n",
    "y = raw['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 3271, 0: 4342})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = MAX_VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(data.values)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22700"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordidx = tokenizer.word_index\n",
    "Vlength = len(wordidx)\n",
    "Vlength #unique tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train) #keep pre-padding since LSTM would lose the information otherwise\n",
    "seq_length = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6090, 32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1523, 32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pad_sequences(X_test,maxlen=seq_length)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "D = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(D=D, X = X_train, y=y_train):\n",
    "    i = Input(shape=(seq_length,))\n",
    "    x = Embedding(Vlength+1, D)(i)\n",
    "    x = Conv1D(16, 1, activation = 'relu')(x)\n",
    "    x = MaxPooling1D(1)(x)\n",
    "    x = Conv1D(32, 1, activation = 'relu')(x)\n",
    "    x = MaxPooling1D(1)(x)\n",
    "    x = Conv1D(64, 1, activation = 'relu')(x)\n",
    "    x = MaxPooling1D(1)(x)\n",
    "    x = Conv1D(128, 1, activation = 'relu')(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "    model = Model(i,x)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    ES = keras.callbacks.EarlyStopping(monitor = 'val_accuracy', patience = 2, restore_best_weights = True)\n",
    "    model.fit(X, y, epochs = 20, callbacks = [ES], validation_data = (X_test, y_test), verbose = 2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "191/191 - 2s - loss: 0.6489 - accuracy: 0.6107 - val_loss: 0.6171 - val_accuracy: 0.7032\n",
      "Epoch 2/20\n",
      "191/191 - 1s - loss: 0.5096 - accuracy: 0.7739 - val_loss: 0.5541 - val_accuracy: 0.7196\n",
      "Epoch 3/20\n",
      "191/191 - 1s - loss: 0.3543 - accuracy: 0.8534 - val_loss: 0.5736 - val_accuracy: 0.7511\n",
      "Epoch 4/20\n",
      "191/191 - 1s - loss: 0.2336 - accuracy: 0.9061 - val_loss: 0.6307 - val_accuracy: 0.7321\n",
      "Epoch 5/20\n",
      "191/191 - 1s - loss: 0.1653 - accuracy: 0.9360 - val_loss: 0.7159 - val_accuracy: 0.7262\n"
     ]
    }
   ],
   "source": [
    "model_2 = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_alt(D=D, X = X_train, y=y_train):\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        Embedding(Vlength+1, D),\n",
    "        Conv1D(16, 3, activation = 'relu'),\n",
    "        MaxPooling1D(3),\n",
    "        Conv1D(32, 3, activation = 'relu'),\n",
    "        MaxPooling1D(3),\n",
    "        Conv1D(64, 2, activation = 'relu'),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    ES = keras.callbacks.EarlyStopping(monitor = 'val_accuracy', patience = 2, restore_best_weights = True)\n",
    "    model.fit(X, y, epochs = 20, callbacks = [ES], validation_data = (X_test, y_test), verbose = 2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "191/191 - 1s - loss: 0.6286 - accuracy: 0.6361 - val_loss: 0.4969 - val_accuracy: 0.7649\n",
      "Epoch 2/20\n",
      "191/191 - 1s - loss: 0.3814 - accuracy: 0.8445 - val_loss: 0.4811 - val_accuracy: 0.7761\n",
      "Epoch 3/20\n",
      "191/191 - 1s - loss: 0.2189 - accuracy: 0.9204 - val_loss: 0.5654 - val_accuracy: 0.7748\n",
      "Epoch 4/20\n",
      "191/191 - 1s - loss: 0.1399 - accuracy: 0.9521 - val_loss: 0.6609 - val_accuracy: 0.7433\n"
     ]
    }
   ],
   "source": [
    "model_alt = train_model_alt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_alt2(D=D, X = X_train, y=y_train):\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        Embedding(Vlength+1, D),\n",
    "        Conv1D(16, 3, activation = 'relu'),\n",
    "        MaxPooling1D(3),\n",
    "        Conv1D(32, 3, activation = 'relu'),\n",
    "        MaxPooling1D(3),\n",
    "        Conv1D(64, 2, activation = 'relu'),\n",
    "        MaxPooling1D(1),\n",
    "        Conv1D(128, 1, activation = 'relu'),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    ES = keras.callbacks.EarlyStopping(monitor = 'val_accuracy', patience = 2, restore_best_weights = True)\n",
    "    model.fit(X, y, epochs = 20, callbacks = [ES], validation_data = (X_test, y_test), verbose = 2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "191/191 - 1s - loss: 0.6296 - accuracy: 0.6425 - val_loss: 0.4978 - val_accuracy: 0.7735\n",
      "Epoch 2/20\n",
      "191/191 - 1s - loss: 0.3801 - accuracy: 0.8404 - val_loss: 0.4806 - val_accuracy: 0.7866\n",
      "Epoch 3/20\n",
      "191/191 - 1s - loss: 0.2001 - accuracy: 0.9319 - val_loss: 0.5808 - val_accuracy: 0.7794\n",
      "Epoch 4/20\n",
      "191/191 - 1s - loss: 0.1356 - accuracy: 0.9539 - val_loss: 0.6779 - val_accuracy: 0.7564\n"
     ]
    }
   ],
   "source": [
    "model_alt2 = train_model_alt2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_alt3(D=D, X = X_train, y=y_train):\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        Embedding(Vlength+1, D),\n",
    "        Conv1D(32, 3, activation = 'relu'),\n",
    "        MaxPooling1D(3),\n",
    "        Conv1D(64, 3, activation = 'relu'),\n",
    "        MaxPooling1D(3),\n",
    "        Conv1D(128, 2, activation = 'relu'),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    ES = keras.callbacks.EarlyStopping(monitor = 'val_accuracy', patience = 2, restore_best_weights = True)\n",
    "    model.fit(X, y, epochs = 20, callbacks = [ES], validation_data = (X_test, y_test), verbose = 2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "191/191 - 1s - loss: 0.5978 - accuracy: 0.6721 - val_loss: 0.4860 - val_accuracy: 0.7748\n",
      "Epoch 2/20\n",
      "191/191 - 1s - loss: 0.3497 - accuracy: 0.8565 - val_loss: 0.5489 - val_accuracy: 0.7741\n",
      "Epoch 3/20\n",
      "191/191 - 1s - loss: 0.1960 - accuracy: 0.9307 - val_loss: 0.6195 - val_accuracy: 0.7715\n"
     ]
    }
   ],
   "source": [
    "model_alt3 = train_model_alt3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test = pd.read_csv('test.csv', index_col = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = raw_test['text']\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "test_data = pad_sequences(test_sequences, maxlen=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model_2,model_alt,model_alt2,model_alt3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3, pred4, pred5, pred6 = [1 if n >= 0.5 else 0 for n in model_2.predict(test_data)], [1 if n >= 0.5 else 0 for n in model_alt.predict(test_data)], [1 if n >= 0.5 else 0 for n in model_alt2.predict(test_data)], [1 if n >= 0.5 else 0 for n in model_alt3.predict(test_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission3 = pd.DataFrame(index = raw_test.index, data = pred3)\n",
    "submission4 = pd.DataFrame(index = raw_test.index, data = pred4)\n",
    "submission5 = pd.DataFrame(index = raw_test.index, data = pred5)\n",
    "submission6 = pd.DataFrame(index = raw_test.index, data = pred6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission3.columns = ['target']\n",
    "submission4.columns = ['target']\n",
    "submission5.columns = ['target']\n",
    "submission6.columns = ['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission3.to_csv('sub3.csv')\n",
    "submission4.to_csv('sub4.csv')\n",
    "submission5.to_csv('sub5.csv')\n",
    "submission6.to_csv('sub6.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output of this notebook scored a public score of 0.76892 (sub5)\n",
    "\n",
    "So far, a CNN approach does not seem to beat the LSTM approach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
