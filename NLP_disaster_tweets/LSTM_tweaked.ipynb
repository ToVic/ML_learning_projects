{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid',palette='muted',font_scale=1.5)\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 16,10 \n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import LSTM, Embedding\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('train.csv',index_col='id')\n",
    "raw = raw.drop(['keyword','location'], axis=1)\n",
    "data = raw['text']\n",
    "y = raw['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting shenanigans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#remove url\n",
    "def remove_url(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.apply(lambda x: remove_url(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove html\n",
    "def remove_html(text):\n",
    "    html = re.compile(r'<.*?>')\n",
    "    return html.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.apply(lambda x: remove_html(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove f...ing emojis, had to google this\n",
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\" #emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\" #symbols&pics\n",
    "                               u\"\\U0001F680-\\U0001F6FF\" #transportation pic\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\" #flags\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"    \n",
    "                               \"]+\", flags = re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.apply(lambda x: remove_emojis(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation\n",
    "import string\n",
    "def remove_punct(text):\n",
    "    signs = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(signs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = MAX_VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(data.values)\n",
    "X_train = tokenizer.texts_to_sequences(data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18104"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordidx = tokenizer.word_index\n",
    "Vlength = len(wordidx)\n",
    "Vlength #unique tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 31) (7613,)\n"
     ]
    }
   ],
   "source": [
    "X_train = pad_sequences(X_train)\n",
    "y_train = y.copy()\n",
    "seq_length = X_train.shape[1]\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweaking the RNN model\n",
    "The goal is to get closer to t1 of .85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(D, X = X_train, y=y_train):\n",
    "    i = Input(shape=(seq_length,))\n",
    "    x = Embedding(Vlength+1,D)(i)\n",
    "    x = keras.layers.Bidirectional(LSTM(D, return_sequences = True, recurrent_dropout = 0.3))(x)\n",
    "    x = keras.layers.Bidirectional(LSTM(D, return_sequences = True, recurrent_dropout = 0.3))(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "#    x = Dense(128, activation = 'relu')(x)\n",
    "#    x = keras.layers.Dropout(0.5)(x)\n",
    "#    x = Dense(64, activation = 'relu')(x)\n",
    "#    x = keras.layers.Dropout(0.5)(x)\n",
    "    x = Dense(1, activation = 'sigmoid')(x)\n",
    "    adam = keras.optimizers.Adam(lr=0.001)\n",
    "    model = Model(i,x)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    ES = keras.callbacks.EarlyStopping(monitor = 'val_accuracy', patience = 2, restore_best_weights = False)\n",
    "    history = model.fit(X, y, epochs = 20, callbacks = [ES], validation_split = 0.1, verbose = 2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "215/215 - 9s - loss: 0.5837 - accuracy: 0.6914 - val_loss: 0.4407 - val_accuracy: 0.7966\n",
      "Epoch 2/20\n",
      "215/215 - 8s - loss: 0.3413 - accuracy: 0.8672 - val_loss: 0.4669 - val_accuracy: 0.7730\n",
      "Epoch 3/20\n",
      "215/215 - 8s - loss: 0.2002 - accuracy: 0.9349 - val_loss: 0.5188 - val_accuracy: 0.7874\n"
     ]
    }
   ],
   "source": [
    "model = train_model(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "215/215 - 8s - loss: 0.5676 - accuracy: 0.6941 - val_loss: 0.4454 - val_accuracy: 0.7992\n",
      "Epoch 2/20\n",
      "215/215 - 8s - loss: 0.3282 - accuracy: 0.8702 - val_loss: 0.4481 - val_accuracy: 0.7913\n",
      "Epoch 3/20\n",
      "215/215 - 8s - loss: 0.1962 - accuracy: 0.9323 - val_loss: 0.4968 - val_accuracy: 0.7782\n"
     ]
    }
   ],
   "source": [
    "model1 = train_model(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "215/215 - 31s - loss: 0.5175 - accuracy: 0.7454 - val_loss: 0.4387 - val_accuracy: 0.8031\n",
      "Epoch 2/20\n",
      "215/215 - 30s - loss: 0.2832 - accuracy: 0.8908 - val_loss: 0.4905 - val_accuracy: 0.7441\n",
      "Epoch 3/20\n",
      "215/215 - 30s - loss: 0.1626 - accuracy: 0.9463 - val_loss: 0.5503 - val_accuracy: 0.7638\n"
     ]
    }
   ],
   "source": [
    "model2 = train_model(128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering the texts and getting rid of all the redundant stuff does not really help in this case.\n",
    "\n",
    "..or does it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(data):\n",
    "    data = data.apply(lambda x: remove_url(x))\n",
    "    data = data.apply(lambda x: remove_html(x))\n",
    "    data = data.apply(lambda x: remove_emojis(x))\n",
    "    data = data.apply(lambda x: remove_punct(x))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test = pd.read_csv('test.csv', index_col='id')\n",
    "raw_test = raw_test.drop(['keyword','location'], axis=1)\n",
    "test_data = raw_test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pipeline(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tokenizer.texts_to_sequences(test_data.values)\n",
    "X_test = pad_sequences(X_test, maxlen = seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred10 = [1 if n >= 0.5 else 0 for n in model1.predict(X_test)]\n",
    "submission10 = pd.DataFrame(index = raw_test.index, data = pred10)\n",
    "submission10.columns = ['target']\n",
    "submission10.to_csv('sub10.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meh, 0.77321\n",
    "what about threshold movement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_exp = [1 if n >= 0.6 else 0 for n in model1.predict(X_test)]\n",
    "submission11 = pd.DataFrame(index = raw_test.index, data = pred_exp)\n",
    "submission11.columns = ['target']\n",
    "submission11.to_csv('sub11.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slightly less meh, 0.77750"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
